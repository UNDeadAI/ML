{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Assignment 4\n",
    "\n",
    "### Oscar Fabián Ñáñez Núñez - Juan Camilo Calero Espinosa\n",
    "### ofnanezn - jccaleroe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pylab as pl\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import operator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a)\n",
    "![title](nn.jpg)\n",
    "where $a_{i}=\\sum_{j}w_{j}^{i}z_{j}$ , $z_{i}=f_{i}(a_{i})$ for\n",
    "$i=1,2,3,4$, $z_{5}=a_{5}$ (an input neuron), $f_{2}(x)=\\textrm{relu}(x)$,\n",
    "and $f_{1}(x)=f_{3}(x)=f_{4}(x)=\\textrm{sigmoid}(x)$. $\\textrm{relu}(x)$\n",
    "corresponds to a rectifier linear unit transfer function defined as:\n",
    "$$\n",
    "\\textrm{relu}(x)=\\begin{cases}\n",
    "x & \\textrm{if }x\\ge0\\\\\n",
    "0 & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "1.a Write a function to simulate the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    sigma_x = 1./(1+np.exp(-x))\n",
    "    if not derivative:\n",
    "        return sigma_x\n",
    "    else:\n",
    "        return sigma_x * (1 - sigma_x)\n",
    "    \n",
    "def relu(x, derivative=False):\n",
    "    if not derivative:\n",
    "        return max(0,x)\n",
    "    else:\n",
    "        return (1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(x, w):\n",
    "    '''\n",
    "    x: input value for neuron 5\n",
    "    w: weights array in the following order\n",
    "       [w13, w12, w14, w32, w42, w53, w54]\n",
    "    Returns: a pair of arrays (a, z), where \n",
    "             a has the activation values for each neuron, and\n",
    "             z the output values for each neuron\n",
    "    '''\n",
    "    w31, w21, w41, w32, w42, w53, w54 = w[0], w[1], w[2], w[3], w[4], w[5], w[6]\n",
    "    z = np.zeros(5)\n",
    "    a = np.zeros(5)\n",
    "    # your code here\n",
    "    a[4] = x\n",
    "    z[4] = a[4]\n",
    "    a[3] = w54*z[4]\n",
    "    z[3] = sigmoid(a[3])\n",
    "    a[2] = w53*z[4]\n",
    "    z[2] = sigmoid(a[2])\n",
    "    a[1] = w32*z[2] + w42*z[3]\n",
    "    z[1] = relu(a[1])\n",
    "    a[0] = w31*z[2] + w21*z[1] + w41*z[3]\n",
    "    z[0] = sigmoid(a[0])\n",
    "    return (a, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b)\n",
    "Deduce the equations to calculate $\\delta_{i}$ (the error value per neuron) for all the neurons. Write a function that given a training sample and the weights of the network calculate $\\delta_{i}$ for each neuron. Assume a square error loss:\n",
    "$$ L_2(f, D) =\\sum_{(x_{i},r_{i}) \\in D} (r_i - f(x_i))^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp(x, y, w):\n",
    "    '''\n",
    "    x: input value for neuron 5\n",
    "    y: output value for neuron 1\n",
    "    w: weights array in the following order\n",
    "       [w13, w12, w14, w32, w42, w53, w54]\n",
    "    Returns: an arr6ay delta with the delta values for each\n",
    "             neuron\n",
    "    '''\n",
    "    delta = np.zeros(5)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c) \n",
    "Write a function to update the neural network weights when a new training sample is shown using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y, w, eta):\n",
    "    '''\n",
    "    x: input value for neuron 5\n",
    "    y: output value for neuron 1\n",
    "    w: weights array in the following order\n",
    "       [w13, w12, w14, w32, w42, w53, w54]\n",
    "    eta: learning rate\n",
    "    Returns: updated w array\n",
    "    '''\n",
    "    # Calculate dw\n",
    "    # Your code here\n",
    "    dw = np.zeros(5)\n",
    "    w = w - eta*dw\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d )\n",
    "Use the previous function to train the network with these [training samples](http://fagonzalezo.github.io/ml/samples_assign4.txt).  Plot the evolution of the error and the predictions of the trained network. Write down the weights of the trained network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (1.0) The hangman\n",
    "\n",
    "Design a function able to find the missing characters from a word. The function must work as follows:\n",
    "\n",
    "```\n",
    ">>> hangman(\"pe_p_e\")\n",
    "'people'\n",
    "\n",
    ">>> hangman(\"phi__sop_y\")\n",
    "'philosophy'\n",
    "\n",
    ">>> hangman(\"si_nif_c_nc_\")\n",
    "'significance'\n",
    "\n",
    ">>> hangman(\"kn__l_d_e\")\n",
    "'knowledge'\n",
    "\n",
    ">>> hangman(\"inte_r_ga_i_n\")\n",
    "'interrogation'\n",
    "```\n",
    "\n",
    "The function must be able to deal with up to 4 unknowns in arbitrary length words. The function must work in a reasonable time (max 30 seconds in a laptop). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hangman(word):\n",
    "    ### your code here\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. (2.0) Bird classification. \n",
    "\n",
    "1. Direct prediction\n",
    "   * Download the dataset birds from http://www-cvr.ai.uiuc.edu/ponce_grp/data/.\n",
    "   * Use [Keras](https://keras.io/) and the [MobileNet](https://keras.io/applications/#mobilenet) pre-trained model, to classify the images in the birds dataset. Construct a confusion matrix that relates the bird classes with the 10 most frequent classes from ImageNet predicted by the model.\n",
    "2. Transfer learning\n",
    "   * Use the pre-trained MobileNet model as a feature extractor. Create a new model that replaces the top part of MobileNet with two layers of 256 and 6 neurons respectively.\n",
    "   * Change the attribute trainable of the other layers to be False. This will prevent the weights of these layers to be changed during training.\n",
    "   * Train the model with the training images from the bird dataset. \n",
    "   * Evaluate the performance over the test dataset reporting the results in a confusion matrix. Discuss the results. \n",
    "3. Fine tuning\n",
    "   * Repeat the experiment from the last question, but this time allow all the layers to be trained. \n",
    "   * Compare and discuss the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
