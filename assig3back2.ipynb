{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as AL\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from threading import Thread\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import plotly\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Subsequence Kernel\n",
    "This implementation uses dynamic programming to caculate the number of common string subsequences of length n of two strings, the distance between characters in the subsequence is penalized with a decay factor $\\lambda$, the implementatin consist of n+1 iterations, where each iteration creates a matrix and each position j,k tells how many common subsequences of length i have been counted at the moment and wich decay the subsequece has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssk (a, b, n, lam):\n",
    "    Kp = np.zeros((n + 1, len(a), len(b)), dtype=np.float64)\n",
    "    Kp[0, :] = 1.0\n",
    "    for i in range(n):\n",
    "        for j in range(len(a) - 1):\n",
    "            Kpp = 0.0\n",
    "            for k in range(len(b) - 1):\n",
    "                Kpp = lam * (Kpp + lam * int(a[j] == b[k]) * Kp[i, j, k])           \n",
    "                Kp[i+1, j+1, k+1] = lam * Kp[i+1, j, k+1] + Kpp\n",
    "                \n",
    "    K = 0.0\n",
    "    for j in range(len(a)):\n",
    "        for k in range(len(b)):\n",
    "            K += lam * lam * int(a[j] == b[k]) * Kp[n-1, j, k]\n",
    "    print(Kp)\n",
    "    return  K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 1. 1. 1.]\n",
      "  [0. 1. 2. 2.]\n",
      "  [0. 1. 2. 3.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 1. 1.]\n",
      "  [0. 0. 1. 3.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssk(\"cvab\", \"cvag\", 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams kernel \n",
    "### Implementation of the n-gram kernel taken from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngk(doc1, doc2, n=2):\n",
    "    # Counts the occurences of unique n-grams\n",
    "    ngrams = CountVectorizer(analyzer='char', ngram_range=(n, n)).fit_transform([doc1, doc2])\n",
    "\n",
    "    # Normalize\n",
    "    #a, b = TfidfTransformer().fit_transform(ngrams).toarray()\n",
    "    a, b = ngrams.toarray()\n",
    "    return np.dot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = np.genfromtxt('words/english5000.txt',dtype='str')\n",
    "spanish = np.genfromtxt('words/spanish5000.txt',dtype='str')\n",
    "sl = np.zeros(spanish.shape)\n",
    "el = np.full(spanish.shape, 1)\n",
    "X = np.concatenate((spanish, english), axis=0)\n",
    "Y = np.concatenate((sl, el), axis=0)\n",
    "\n",
    "englishTest = np.genfromtxt('words/englishTest100.txt',dtype='str')\n",
    "spanishTest = np.genfromtxt('words/spanishTest100.txt',dtype='str')\n",
    "slt = np.zeros(spanishTest.shape)\n",
    "elt = np.full(spanishTest.shape, 1)\n",
    "XT = np.concatenate((spanishTest, englishTest), axis=0)\n",
    "YT = np.concatenate((slt, elt), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSK Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram = np.zeros((X.shape[0], X.shape[0]))\n",
    "gramT = np.zeros((XT.shape[0], X.shape[0]))\n",
    "def sskClassifier(n, lam):\n",
    "    #t = time()\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            gram[i][j] = ssk(X[i], X[j], n, lam)\n",
    "\n",
    "    #print(\"gram preprocessed\")\n",
    "    #print(round(time()-t))\n",
    "\n",
    "    clf = svm.SVC(kernel='precomputed')\n",
    "    clf.fit(gram, Y)\n",
    "\n",
    "    #t = time()\n",
    "    for i in range(XT.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            gramT[i][j] = ssk(XT[i], X[j], n, lam)\n",
    "\n",
    "    #print(\"test gram preprocessed\")\n",
    "    #print(round(time()-t))\n",
    "    Z = clf.predict(gramT)\n",
    "    #print(Z)\n",
    "    #print(YT)\n",
    "    #print(XT)\n",
    "    a = accuracy_score(YT, Z)\n",
    "    print(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n  2 lamda  0.1\n",
      "0.715\n",
      "n  2 lamda  0.2\n",
      "0.72\n",
      "n  2 lamda  0.3\n",
      "0.705\n",
      "n  2 lamda  0.4\n",
      "0.695\n",
      "n  2 lamda  0.5\n",
      "0.745\n",
      "n  2 lamda  0.6\n",
      "0.77\n",
      "n  2 lamda  0.7\n",
      "0.775\n",
      "n  2 lamda  0.8\n",
      "0.73\n",
      "n  2 lamda  0.9\n",
      "0.74\n",
      "n  2 lamda  1.0\n",
      "0.725\n",
      "n  3 lamda  0.1\n",
      "0.59\n",
      "n  3 lamda  0.2\n",
      "0.585\n",
      "n  3 lamda  0.3\n",
      "0.61\n",
      "n  3 lamda  0.4\n",
      "0.665\n",
      "n  3 lamda  0.5\n",
      "0.705\n",
      "n  3 lamda  0.6\n",
      "0.75\n",
      "n  3 lamda  0.7\n",
      "0.745\n",
      "n  3 lamda  0.8\n",
      "0.76\n",
      "n  3 lamda  0.9\n",
      "0.72\n",
      "n  3 lamda  1.0\n",
      "0.71\n",
      "n  4 lamda  0.1\n",
      "0.61\n",
      "n  4 lamda  0.2\n",
      "0.65\n",
      "n  4 lamda  0.3\n",
      "0.67\n",
      "n  4 lamda  0.4\n",
      "0.62\n",
      "n  4 lamda  0.5\n",
      "0.565\n",
      "n  4 lamda  0.6\n",
      "0.555\n",
      "n  4 lamda  0.7\n",
      "0.735\n",
      "n  4 lamda  0.8\n",
      "0.69\n",
      "n  4 lamda  0.9\n",
      "0.685\n",
      "n  4 lamda  1.0\n",
      "0.65\n",
      "n  5 lamda  0.1\n",
      "0.525\n",
      "n  5 lamda  0.2\n",
      "0.515\n",
      "n  5 lamda  0.3\n",
      "0.505\n",
      "n  5 lamda  0.4\n",
      "0.5\n",
      "n  5 lamda  0.5\n",
      "0.5\n",
      "n  5 lamda  0.6\n",
      "0.5\n",
      "n  5 lamda  0.7\n",
      "0.615\n",
      "n  5 lamda  0.8\n",
      "0.66\n",
      "n  5 lamda  0.9\n",
      "0.625\n",
      "n  5 lamda  1.0\n",
      "0.62\n",
      "n  6 lamda  0.1\n",
      "0.5\n",
      "n  6 lamda  0.2\n",
      "0.5\n",
      "n  6 lamda  0.3\n",
      "0.5\n",
      "n  6 lamda  0.4\n",
      "0.5\n",
      "n  6 lamda  0.5\n",
      "0.5\n",
      "n  6 lamda  0.6\n",
      "0.5\n",
      "n  6 lamda  0.7\n",
      "0.5\n",
      "n  6 lamda  0.8\n",
      "0.5\n",
      "n  6 lamda  0.9\n",
      "0.54\n",
      "n  6 lamda  1.0\n",
      "0.535\n",
      "n  7 lamda  0.1\n",
      "0.5\n",
      "n  7 lamda  0.2\n",
      "0.5\n",
      "n  7 lamda  0.3\n",
      "0.5\n",
      "n  7 lamda  0.4\n",
      "0.5\n",
      "n  7 lamda  0.5\n",
      "0.5\n",
      "n  7 lamda  0.6\n",
      "0.5\n",
      "n  7 lamda  0.7\n",
      "0.5\n",
      "n  7 lamda  0.8\n",
      "0.5\n",
      "n  7 lamda  0.9\n",
      "0.495\n",
      "n  7 lamda  1.0\n",
      "0.495\n",
      "nMax 2 lamMax 7 value 0.775\n"
     ]
    }
   ],
   "source": [
    "nMax, lamMax, tmp = 0, 0, 0\n",
    "for n in range(2, 8):\n",
    "    for lam in range(1, 11):\n",
    "        print(\"n \", n, \"lamda \", lam/10.0)\n",
    "        aux = sskClassifier(n, lam/10.0)\n",
    "        if aux > tmp:\n",
    "            tmp = aux\n",
    "            nMax = n\n",
    "            lamMax = lam\n",
    "\n",
    "print(\"nMax\", nMax, \"lamMax\", lamMax, \"value\", tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters:\n",
    "### n= 2, lambda = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGK Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = np.genfromtxt('words/english4000.txt',dtype='str')\n",
    "spanish = np.genfromtxt('words/spanish4000.txt',dtype='str')\n",
    "sl = np.zeros(spanish.shape)\n",
    "el = np.full(spanish.shape, 1)\n",
    "X = np.concatenate((spanish, english), axis=0)\n",
    "Y = np.concatenate((sl, el), axis=0)\n",
    "\n",
    "englishTest = np.genfromtxt('words/englishTest100.txt',dtype='str')\n",
    "spanishTest = np.genfromtxt('words/spanishTest100.txt',dtype='str')\n",
    "slt = np.zeros(spanishTest.shape)\n",
    "elt = np.full(spanishTest.shape, 1)\n",
    "XT = np.concatenate((spanishTest, englishTest), axis=0)\n",
    "YT = np.concatenate((slt, elt), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 198)\n",
      "gram2 preprocessed\n",
      "145\n",
      "(20, 198)\n",
      "test gram2 preprocessed\n",
      "16\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "['analizado' 'ambientes' 'amaban' 'almanaque' 'alisa' 'alimenticia'\n",
      " 'alimentado' 'alcancé' 'albóndigas' 'albin' 'freshet' 'grovel'\n",
      " 'harlequin' 'jewry' 'megaphone' 'parallelogram' 'plummet' 'sublunary'\n",
      " 'typographical' 'ussr']\n"
     ]
    }
   ],
   "source": [
    "def ngkClassifier(n):\n",
    "    #t = time()\n",
    "    gram2 = np.zeros((X.shape[0], X.shape[0]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            gram2[i][j] = ngk(X[i], X[j], n)\n",
    "\n",
    "    #print(\"gram2 preprocessed\")\n",
    "    #print(round(time()-t))\n",
    "\n",
    "    clf2 = svm.SVC(kernel='precomputed')\n",
    "    clf2.fit(gram2, Y)\n",
    "\n",
    "    #t = time()\n",
    "    gramT2 = np.zeros((XT.shape[0], X.shape[0]))\n",
    "    for i in range(XT.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            gramT2[i][j] = ngk(XT[i], X[j], n)\n",
    "\n",
    "    #print(\"test gram2 preprocessed\")\n",
    "    #print(round(time()-t))\n",
    "\n",
    "    Z2 = clf2.predict(gramT2)\n",
    "    #print(Z2)\n",
    "    #print(YT)\n",
    "    #print(XT)\n",
    "    a = accuracy_score(YT, Z2)\n",
    "    print(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n  1\n",
      "0.715\n",
      "n  2\n",
      "0.785\n",
      "n  3\n",
      "0.71\n",
      "n  4\n",
      "0.695\n",
      "Max n: 2 value: 0.785\n"
     ]
    }
   ],
   "source": [
    "nMax, tmp = 0, 0\n",
    "for n in range(1, 5):\n",
    "    print(\"n \", n)\n",
    "    aux = ngkClassifier(n)\n",
    "    if aux > tmp:\n",
    "        tmp = aux\n",
    "        nMax = n\n",
    "        \n",
    "print(\"Max n:\", nMax, \"value:\", tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = np.genfromtxt('words/english4000.txt',dtype='str')\n",
    "spanish = np.genfromtxt('words/spanish4000.txt',dtype='str')\n",
    "sl = np.zeros(spanish.shape)\n",
    "el = np.full(spanish.shape, 1)\n",
    "X = np.concatenate((spanish, english), axis=0)\n",
    "Y = np.concatenate((sl, el), axis=0)\n",
    "\n",
    "englishTest = np.genfromtxt('words/englishTest100.txt',dtype='str')\n",
    "spanishTest = np.genfromtxt('words/spanishTest100.txt',dtype='str')\n",
    "slt = np.zeros(spanishTest.shape)\n",
    "elt = np.full(spanishTest.shape, 1)\n",
    "XT = np.concatenate((spanishTest, englishTest), axis=0)\n",
    "YT = np.concatenate((slt, elt), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sskClassifier(2, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
